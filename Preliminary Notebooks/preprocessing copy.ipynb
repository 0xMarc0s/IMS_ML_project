{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Preprocessing - but using embedded feature selection methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import CategoricalNB, MultinomialNB, GaussianNB\n",
    "from sklearn.model_selection import RepeatedKFold, cross_val_score\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../our data/no_outliers.csv\")\n",
    "df_test = pd.read_csv(\"../data/obesity_test.csv\")\n",
    "\n",
    "df_test = df_test.drop(columns=[\"region\", \"marrital_status\"])\n",
    "\n",
    "# Scale and KNN-impute data\n",
    "scalers = {} # Preserve scalers for antitransformation\n",
    "\n",
    "columns = ['age', 'height', 'weight']\n",
    "scaler = StandardScaler()\n",
    "imputer = KNNImputer(n_neighbors=5, weights='uniform')\n",
    "\n",
    "df_train[columns] = scaler.fit_transform(df_train[columns])\n",
    "df_test[columns] = scaler.transform(df_test[columns])\n",
    "\n",
    "\n",
    "# Impute\n",
    "df_train[columns] = imputer.fit_transform(df_train[columns])\n",
    "df_test[columns] = imputer.transform(df_test[columns])\n",
    "\n",
    "# Transform back \n",
    "df_train[columns] = scaler.inverse_transform(df_train[columns])\n",
    "df_test[columns] = scaler.inverse_transform(df_test[columns])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_bmi_comprehensive(row):\n",
    "    \"\"\"\n",
    "    Classify BMI based on age and BMI value.\n",
    "\n",
    "    Input:\n",
    "    row: A Pandas row with 'weight', 'height', and 'age' columns.\n",
    "\n",
    "    Output:\n",
    "    Returns a string that classifies the individual into BMI categories.\n",
    "    \"\"\"\n",
    "    # Check if weight and height are valid\n",
    "    if row['height'] <= 0 or row['weight'] <= 0:\n",
    "        return 'Invalid data'\n",
    "\n",
    "    # Calculate BMI\n",
    "    bmi = row['weight'] / (row['height'] ** 2)\n",
    "\n",
    "    # Age group: Children (2-19 years)\n",
    "    if 2 <= row['age'] < 20:\n",
    "        if bmi < 14:\n",
    "            return 0 # Underweight\n",
    "        elif 14 <= bmi < 18:\n",
    "            return 1 # Normal weight\n",
    "        elif 18 <= bmi < 21:\n",
    "            return 2 # Overweight\n",
    "        else:\n",
    "            return 3 # Obesity 1\n",
    "\n",
    "    # Age group: Adults (20-64 years)\n",
    "    elif 20 <= row['age'] < 65:\n",
    "        if bmi < 18.5:\n",
    "            return 0 # \"Underweight\"\n",
    "        elif 18.5 <= bmi < 25:\n",
    "            return 1 # \"Healthy Weight\"\n",
    "        elif 25 <= bmi < 30:\n",
    "            return 2 #\"Overweight\"\n",
    "        elif 30<= bmi < 35:\n",
    "            return 3 #\"Obese Class 1\"\n",
    "        elif 35 <= bmi < 40:\n",
    "            return 4 #\"Obese Class 2\"\n",
    "        else:\n",
    "            return 5 #\"Obese Class 3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add BMI\n",
    "df_train['bmi_class'] = df_train.apply(lambda row: classify_bmi_comprehensive(row), axis=1)\n",
    "df_test['bmi_class'] = df_test.apply(lambda row: classify_bmi_comprehensive(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        5 or more\n",
       "1      No Activity\n",
       "2           1 to 2\n",
       "3           1 to 2\n",
       "4           3 to 4\n",
       "          ...     \n",
       "495    No Activity\n",
       "496    No Activity\n",
       "497    No Activity\n",
       "498    No Activity\n",
       "499         3 to 4\n",
       "Name: physical_activity_perweek, Length: 500, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill missing activity with zero\n",
    "df_train['physical_activity_perweek'].fillna('No Activity')\n",
    "df_test['physical_activity_perweek'].fillna('No Activity')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashmap = {\n",
    "\"Never\": 0,\n",
    "\"Sometimes\": 1,\n",
    "\"Frequently\": 2,\n",
    "\"Always\": 3,\n",
    "\n",
    "\"No Activity\": 0,\n",
    "\"up to 2\": 1,\n",
    "\"up to 5\": 2,\n",
    "\"more than 5\": 3,\n",
    "\n",
    "\"less than 1\": 1,\n",
    "\"1 to 2\": 2,\n",
    "\"more than 2\": 3,\n",
    "\"3 to 4\": 4,\n",
    "\"5 or more\": 5,\n",
    "\n",
    "\"Bicycle\": 1,\n",
    "\"Car\": 4,\n",
    "\"Motorbike\": 3,\n",
    "\"Public\": 2,\n",
    "\"Walk\": 0,\n",
    "\n",
    "\"no\": 0,\n",
    "\"yes\": 1,\n",
    "\n",
    "\"Male\": 0,\n",
    "\"Female\": 1\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_43700\\722892098.py:20: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_train[target] = df_train[target].replace(hashmap)\n",
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_43700\\722892098.py:21: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_test[target]= df_test[target].replace(hashmap)\n"
     ]
    }
   ],
   "source": [
    "# Manually encode data\n",
    "\n",
    "columns = ['alcohol_freq',\n",
    " 'caloric_freq',\n",
    " 'devices_perday',\n",
    " 'eat_between_meals',\n",
    " 'gender',\n",
    " 'monitor_calories',\n",
    " 'parent_overweight',\n",
    " 'physical_activity_perweek',\n",
    " 'smoke',\n",
    " 'transportation',\n",
    " 'veggies_freq',\n",
    " 'water_daily',\n",
    " 'bmi_class',\n",
    " 'meals_perday',\n",
    " \"siblings\"]\n",
    "\n",
    "for target in columns:\n",
    "    df_train[target] = df_train[target].replace(hashmap)\n",
    "    df_test[target]= df_test[target].replace(hashmap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_iterative.py:825: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Fill rest with KNN or smt else\n",
    "\n",
    "# Scale numerical (again) and KNN-impute data\n",
    "\n",
    "#columnsx = ['age', 'height', 'weight']\n",
    "#scaler = StandardScaler()\n",
    "imputer = DecisionTreeClassifier()\n",
    "imputer = IterativeImputer(imputer)\n",
    "\n",
    "#df_train[columnsx] = scaler.fit_transform(df_train[columnsx])\n",
    "#df_test[columnsx] = scaler.transform(df_test[columnsx])\n",
    "\n",
    "df_train[columns] = imputer.fit_transform(df_train[columns])\n",
    "df_test[columns] = imputer.transform(df_test[columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_obesity = {\n",
    " 'Normal_Weight': 0,\n",
    " 'Overweight_Level_I': 1,\n",
    " 'Overweight_Level_II': 2,\n",
    " 'Obesity_Type_I': 3,\n",
    " 'Insufficient_Weight': 4,\n",
    " 'Obesity_Type_II': 5,\n",
    " 'Obesity_Type_III': 6\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Normal_Weight',\n",
       " 'Overweight_Level_I',\n",
       " 'Overweight_Level_II',\n",
       " 'Obesity_Type_I',\n",
       " 'Insufficient_Weight',\n",
       " 'Obesity_Type_II',\n",
       " 'Obesity_Type_III']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['obese_level'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Normal_Weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m X \u001b[38;5;241m=\u001b[39m df_train\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobese_level\u001b[39m\u001b[38;5;124m\"\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     16\u001b[0m y \u001b[38;5;241m=\u001b[39m df_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobese_level\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 18\u001b[0m reg\u001b[38;5;241m.\u001b[39mfit(X, y)\n\u001b[0;32m     20\u001b[0m coef \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(reg\u001b[38;5;241m.\u001b[39mcoef_, index \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mcolumns)\n",
      "File \u001b[1;32mc:\\Users\\ACER\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ACER\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:1644\u001b[0m, in \u001b[0;36mLinearModelCV.fit\u001b[1;34m(self, X, y, sample_weight, **params)\u001b[0m\n\u001b[0;32m   1632\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1633\u001b[0m     \u001b[38;5;66;03m# Need to validate separately here.\u001b[39;00m\n\u001b[0;32m   1634\u001b[0m     \u001b[38;5;66;03m# We can't pass multi_output=True because that would allow y to be\u001b[39;00m\n\u001b[0;32m   1635\u001b[0m     \u001b[38;5;66;03m# csr. We also want to allow y to be 64 or 32 but check_X_y only\u001b[39;00m\n\u001b[0;32m   1636\u001b[0m     \u001b[38;5;66;03m# allows to convert for 64.\u001b[39;00m\n\u001b[0;32m   1637\u001b[0m     check_X_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m   1638\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1639\u001b[0m         dtype\u001b[38;5;241m=\u001b[39m[np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1642\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy_X,\n\u001b[0;32m   1643\u001b[0m     )\n\u001b[1;32m-> 1644\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m   1645\u001b[0m         X, y, validate_separately\u001b[38;5;241m=\u001b[39m(check_X_params, check_y_params)\n\u001b[0;32m   1646\u001b[0m     )\n\u001b[0;32m   1647\u001b[0m     copy_X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mc:\\Users\\ACER\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:648\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    646\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestimator\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m check_y_params:\n\u001b[0;32m    647\u001b[0m         check_y_params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdefault_check_params, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params}\n\u001b[1;32m--> 648\u001b[0m     y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    649\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    650\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32mc:\\Users\\ACER\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1012\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1010\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1012\u001b[0m         array \u001b[38;5;241m=\u001b[39m _asarray_with_order(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m   1014\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1015\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m   1016\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ACER\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:751\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[0;32m    749\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 751\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39masarray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    753\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    754\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "File \u001b[1;32mc:\\Users\\ACER\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:1031\u001b[0m, in \u001b[0;36mSeries.__array__\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m    981\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    982\u001b[0m \u001b[38;5;124;03mReturn the values as a NumPy array.\u001b[39;00m\n\u001b[0;32m    983\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1028\u001b[0m \u001b[38;5;124;03m      dtype='datetime64[ns]')\u001b[39;00m\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1030\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m-> 1031\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(values, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   1032\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_copy_on_write() \u001b[38;5;129;01mand\u001b[39;00m astype_is_view(values\u001b[38;5;241m.\u001b[39mdtype, arr\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m   1033\u001b[0m     arr \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mview()\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Normal_Weight'"
     ]
    }
   ],
   "source": [
    "# Lasso method\n",
    "from sklearn.linear_model import LassoCV\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "def plot_importance(coef,name):\n",
    "    imp_coef = coef.sort_values()\n",
    "    plt.figure(figsize=(8,10))\n",
    "    imp_coef.plot(kind = \"barh\")\n",
    "    plt.title(\"Feature importance using \" + name + \" Model\")\n",
    "    plt.axvline(x=0, color=\"red\", linestyle=\"--\")\n",
    "    plt.show()\n",
    "\n",
    "reg = LassoCV()\n",
    "\n",
    "X = df_train.drop(\"obese_level\", axis=1)\n",
    "y = df_train['obese_level']\n",
    "\n",
    "reg.fit(X, y)\n",
    "\n",
    "coef = pd.Series(reg.coef_, index = X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop(columns='obese_level')\n",
    "y = df_train['obese_level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>meals_perday</th>\n",
       "      <th>parent_overweight</th>\n",
       "      <th>siblings</th>\n",
       "      <th>weight</th>\n",
       "      <th>bmi_class</th>\n",
       "      <th>life</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.62</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.78</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.64</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.73</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.74</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.74</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1603 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  gender  height  meals_perday  parent_overweight  siblings  weight  \\\n",
       "0     21.0     1.0    1.62           3.0                1.0       3.0    64.0   \n",
       "1     23.0     0.0    1.80           3.0                1.0       0.0    77.0   \n",
       "2     20.6     0.0    1.80           3.0                0.0       2.0    87.0   \n",
       "3     22.0     0.0    1.78           1.0                0.0       3.0    90.0   \n",
       "4     22.0     0.0    1.64           3.0                0.0       3.0    53.0   \n",
       "...    ...     ...     ...           ...                ...       ...     ...   \n",
       "1598  21.0     1.0    1.73           3.0                1.0       1.0   131.0   \n",
       "1599  22.0     1.0    1.75           3.0                1.0       0.0   134.0   \n",
       "1600  23.0     1.0    1.75           3.0                1.0       0.0   134.0   \n",
       "1601  24.0     1.0    1.74           3.0                1.0       0.0   133.0   \n",
       "1602  24.0     1.0    1.74           3.0                1.0       0.0   133.0   \n",
       "\n",
       "      bmi_class  life  \n",
       "0           1.0  10.0  \n",
       "1           1.0  14.0  \n",
       "2           2.0  13.0  \n",
       "3           2.0  13.0  \n",
       "4           1.0  13.0  \n",
       "...         ...   ...  \n",
       "1598        5.0  16.0  \n",
       "1599        5.0  14.0  \n",
       "1600        5.0  14.0  \n",
       "1601        5.0  15.0  \n",
       "1602        5.0  15.0  \n",
       "\n",
       "[1603 rows x 9 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.iloc[:, 1:]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up rkf\n",
    "\n",
    "def run(model, X, y):\n",
    "    my_model = model\n",
    "    rkf = RepeatedKFold(n_splits=5)\n",
    "\n",
    "    scores_train = []\n",
    "    scores_val = []\n",
    "\n",
    "    for (train_index, test_index) in rkf.split(X, y):\n",
    "        X_train = X.iloc[train_index]\n",
    "        X_test = X.iloc[test_index]\n",
    "        y_train = y.iloc[train_index]\n",
    "        y_test = y.iloc[test_index]\n",
    "\n",
    "        my_model.fit(X_train, y_train)\n",
    "\n",
    "        report1 = classification_report(y_test, y_hat:=my_model.predict(X_test), output_dict=True)\n",
    "        report2 = classification_report(y_train, y_hat:=my_model.predict(X_train), output_dict=True)\n",
    "\n",
    "        scores_val.append(report1[\"macro avg\"][\"f1-score\"])\n",
    "        scores_train.append(report2[\"macro avg\"][\"f1-score\"])\n",
    "\n",
    "    return np.array(scores_train).mean(), np.array(scores_val).mean()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.9376914093470652)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(RandomForestClassifier(), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.900091427684042)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(DecisionTreeClassifier(), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6744568045474185, 0.6437766690805445)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(LogisticRegression(solver=\"liblinear\"), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8232783940902952, 0.8085095784861465)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(LogisticRegression(solver=\"newton-cg\"), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run(LogisticRegression(solver=\"newton-cholesky\"), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6675767021586867, 0.6598028349360497)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(GaussianNB(), X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
